{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "목표\n",
    "\n",
    "Aruomarker 생성 (기존 코드 활용)\n",
    "\n",
    "Arucomarker 검출 (기존 코드 활용)\n",
    "\n",
    "Arucomarker 카메라에서 인식\n",
    "\n",
    "Arucomarker 상대 위치 인식\n",
    "\n",
    "Arucomarker 정밀도 수정 연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenCV에서 지원하는 ARUCO MARKER의 TYPE에 대한 딕셔너리\n",
    "ARUCO_DICT = {\n",
    "\t\"DICT_4X4_50\": cv2.aruco.DICT_4X4_50,\n",
    "\t\"DICT_4X4_100\": cv2.aruco.DICT_4X4_100,\n",
    "\t\"DICT_4X4_250\": cv2.aruco.DICT_4X4_250,\n",
    "\t\"DICT_4X4_1000\": cv2.aruco.DICT_4X4_1000,\n",
    "\t\"DICT_5X5_50\": cv2.aruco.DICT_5X5_50,\n",
    "\t\"DICT_5X5_100\": cv2.aruco.DICT_5X5_100,\n",
    "\t\"DICT_5X5_250\": cv2.aruco.DICT_5X5_250,\n",
    "\t\"DICT_5X5_1000\": cv2.aruco.DICT_5X5_1000,\n",
    "\t\"DICT_6X6_50\": cv2.aruco.DICT_6X6_50,\n",
    "\t\"DICT_6X6_100\": cv2.aruco.DICT_6X6_100,\n",
    "\t\"DICT_6X6_250\": cv2.aruco.DICT_6X6_250,\n",
    "\t\"DICT_6X6_1000\": cv2.aruco.DICT_6X6_1000,\n",
    "\t\"DICT_7X7_50\": cv2.aruco.DICT_7X7_50,\n",
    "\t\"DICT_7X7_100\": cv2.aruco.DICT_7X7_100,\n",
    "\t\"DICT_7X7_250\": cv2.aruco.DICT_7X7_250,\n",
    "\t\"DICT_7X7_1000\": cv2.aruco.DICT_7X7_1000,\n",
    "\t\"DICT_ARUCO_ORIGINAL\": cv2.aruco.DICT_ARUCO_ORIGINAL,\n",
    "\t\"DICT_APRILTAG_16h5\": cv2.aruco.DICT_APRILTAG_16h5,\n",
    "\t\"DICT_APRILTAG_25h9\": cv2.aruco.DICT_APRILTAG_25h9,\n",
    "\t\"DICT_APRILTAG_36h10\": cv2.aruco.DICT_APRILTAG_36h10,\n",
    "\t\"DICT_APRILTAG_36h11\": cv2.aruco.DICT_APRILTAG_36h11\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pose_esitmation(frame, aruco_dict_type, matrix_coefficients, distortion_coefficients):\n",
    "\n",
    "    '''\n",
    "    frame - 카메라 또는 비디오에서 읽어온 이미지\n",
    "    aruco_dict_type - 사용하는 MARKER의 TYPE (예. 앞서 설명한 코드의 ARUCO_DICT[aruco_type])\n",
    "    matrix_coefficients - 카메라 Calibration 과정 후에 획득한 Intrinsic matrix (내부 행렬)\n",
    "    distortion_coefficients - 카메라 Calibration 과정 후에 획득한 Distortion coefficients (왜곡 계수)\n",
    "    return:\n",
    "    frame - 읽어온 이미지 + MARKER의 축\n",
    "    '''\n",
    "\n",
    "    # 카메라 또는 비디오에서 읽어온 이미지를 흑백으로 변환\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    # 정의한 ARUCO MARKER의 TYPE을\n",
    "    # 컴퓨터가 이해할 수 있는 형태의 언어로 변환하는 부분임\n",
    "    cv2.aruco_dict = cv2.aruco.Dictionary_get(aruco_dict_type)\n",
    "    # 검출을 위한 파라미터 설정하는 부분임\n",
    "    # 일반적으로 default 값을 그대로 사용함\n",
    "    parameters = cv2.aruco.DetectorParameters_create()\n",
    "    # MARKER 검출\n",
    "    corners, ids, rejected_img_points = cv2.aruco.detectMarkers(gray, cv2.aruco_dict,parameters=parameters)\n",
    "        # cameraMatrix=matrix_coefficients,\n",
    "        # distCoeff=distortion_coefficients)\n",
    "\n",
    "    # 하나 이상의 MARKER가 검출됐을 때만 실행되는 부분\n",
    "    if len(corners) > 0:\n",
    "        for i in range(0, len(ids)):\n",
    "            # 각 MARKER의 Pose를 측정 하고 rvec 과 tvec 으로 반환\n",
    "            rvec, tvec, markerPoints = cv2.aruco.estimatePoseSingleMarkers(corners[i], 0.02, matrix_coefficients,\n",
    "                                                                       distortion_coefficients)\n",
    "            # MARKER 테두리 그려주기 (삭제해도 됨)\n",
    "            cv2.aruco.drawDetectedMarkers(frame, corners) \n",
    "\n",
    "            # MARKER 축 그려주기 (삭제해도 됨)\n",
    "            cv2.aruco.drawAxis(frame, matrix_coefficients, distortion_coefficients, rvec, tvec, 0.01)  \n",
    "\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] detecting 'DICT_4X4_50' tags...\n"
     ]
    }
   ],
   "source": [
    "# 인식할 MARKER의 TYPE을 정의해줌\n",
    "aruco_type = \"DICT_4X4_50\"\n",
    "print(\"[INFO] detecting '{}' tags...\".format(aruco_type))\n",
    "arucoDict = cv2.aruco.Dictionary_get(ARUCO_DICT[aruco_type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix_coefficients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m ret, frame \u001b[39m=\u001b[39m capture\u001b[39m.\u001b[39mread()\n\u001b[1;32m      9\u001b[0m \u001b[39m# cv2.imshow(\"VideoFrame\", frame)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m det_frame \u001b[39m=\u001b[39m pose_esitmation(frame, ARUCO_DICT[aruco_type]) \u001b[39m#, (0,0,0,0), (0,0,0,0))\u001b[39;00m\n\u001b[1;32m     12\u001b[0m cv2\u001b[39m.\u001b[39mimshow(\u001b[39m\"\u001b[39m\u001b[39mVideoFrame\u001b[39m\u001b[39m\"\u001b[39m, det_frame)\n\u001b[1;32m     14\u001b[0m \u001b[39mif\u001b[39;00m cv2\u001b[39m.\u001b[39mwaitKey(\u001b[39m1\u001b[39m) \u001b[39m&\u001b[39m \u001b[39m0xFF\u001b[39m \u001b[39m==\u001b[39m \u001b[39mord\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mq\u001b[39m\u001b[39m'\u001b[39m):\n",
      "Cell \u001b[0;32mIn[3], line 29\u001b[0m, in \u001b[0;36mpose_esitmation\u001b[0;34m(frame, aruco_dict_type)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(corners) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     27\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(ids)):\n\u001b[1;32m     28\u001b[0m         \u001b[39m# 각 MARKER의 Pose를 측정 하고 rvec 과 tvec 으로 반환\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m         rvec, tvec, markerPoints \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39maruco\u001b[39m.\u001b[39mestimatePoseSingleMarkers(corners[i], \u001b[39m0.02\u001b[39m, matrix_coefficients,\n\u001b[1;32m     30\u001b[0m                                                                    distortion_coefficients)\n\u001b[1;32m     31\u001b[0m         \u001b[39m# MARKER 테두리 그려주기 (삭제해도 됨)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m         cv2\u001b[39m.\u001b[39maruco\u001b[39m.\u001b[39mdrawDetectedMarkers(frame, corners) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'matrix_coefficients' is not defined"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "capture.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    # cv2.imshow(\"VideoFrame\", frame)\n",
    "    \n",
    "    det_frame = pose_esitmation(frame, ARUCO_DICT[aruco_type], (0,0,0,0), (0,0,0,0))\n",
    "    cv2.imshow(\"VideoFrame\", det_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "capture.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aruco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
